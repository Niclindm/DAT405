{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sTsDfIVKsmL"
   },
   "source": [
    "# DAT405 Introduction to Data Science and AI \n",
    "## 2022-2023, Reading Period 3\n",
    "## Assignment 4: Spam classification using Naïve Bayes \n",
    "This assignmetn has three obligatory questions which will be grades as PASS/FAIL. Questions 4-5 are optional and will not be graded, but can be interesting for students aiming for higher grades.\n",
    "\n",
    "The exercise takes place in this notebook environment where you can chose to use Jupyter or Google Colabs. We recommend you use Google Colabs as it will facilitate remote group-work and makes the assignment less technical. \n",
    "Hints:\n",
    "You can execute certain linux shell commands by prefixing the command with `!`. You can insert Markdown cells and code cells. The first you can use for documenting and explaining your results the second you can use writing code snippets that execute the tasks required.  \n",
    "\n",
    "In this assignment you will implement a Naïve Bayes classifier in Python that will classify emails into spam and non-spam (“ham”) classes.  Your program should be able to train on a given set of spam and “ham” datasets. \n",
    "You will work with the datasets available at https://spamassassin.apache.org/old/publiccorpus/. There are three types of files in this location: \n",
    "-\teasy-ham: non-spam messages typically quite easy to differentiate from spam messages. \n",
    "-\thard-ham: non-spam messages more difficult to differentiate \n",
    "-\tspam: spam messages \n",
    "\n",
    "**Execute the cell below to download and extract the data into the environment of the notebook -- it will take a few seconds.** If you chose to use Jupyter notebooks you will have to run the commands in the cell below on your local computer, with Windows you can use \n",
    "7zip (https://www.7-zip.org/download.html) to decompress the data.\n",
    "\n",
    "**What to submit:** \n",
    "Convert the notebook to a pdf-file and submit it. Make sure all cells are executed so all your code and its results are included. Double check the pdf displays correctly before you submit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Wa37fBwRF-xe"
   },
   "outputs": [],
   "source": [
    "#Download and extract data\n",
    "#!wget https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "#!wget https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
    "#!wget https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "#!tar -xjf 20021010_easy_ham.tar.bz2\n",
    "#!tar -xjf 20021010_hard_ham.tar.bz2\n",
    "#!tar -xjf 20021010_spam.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdH1XTepLjZ3"
   },
   "source": [
    "*The* data is now in the three folders `easy_ham`, `hard_ham`, and `spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "A53Gw00fBLG2"
   },
   "outputs": [],
   "source": [
    "#!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGlWPVnSNzT7"
   },
   "source": [
    "### 1. Preprocessing: \n",
    "Note that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text (in the optional part further down can experiment with filtering out the headers and footers). \n",
    "1.\tWe don’t want to train and test on the same data (it might help to reflect on why if you don't recall). Split the spam and the ham datasets in a training set and a test set. (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`). Use easy_ham for quesions 1 and 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = os.listdir('spam')\n",
    "spam_list = []\n",
    "for x in spam:\n",
    "    with open('spam/'+x, encoding=\"ISO-8859-1\") as f:\n",
    "        text = f.read()\n",
    "    spam_list.append(text)\n",
    "\n",
    "easy_ham = os.listdir('easy_ham')\n",
    "easy_ham_list = []\n",
    "for x in easy_ham:\n",
    "    with open('easy_ham/'+x, encoding=\"ISO-8859-1\") as f:\n",
    "        text = f.read()\n",
    "    easy_ham_list.append(text)\n",
    "\n",
    "hard_ham = os.listdir('hard_ham')\n",
    "hard_ham_list = []\n",
    "for x in hard_ham:\n",
    "    with open('hard_ham/'+x, encoding=\"ISO-8859-1\") as f:\n",
    "        text = f.read()\n",
    "    hard_ham_list.append(text)\n",
    "        \n",
    "\n",
    "hamtrain, hamtest = train_test_split(easy_ham_list, train_size=0.8)\n",
    "spamtrain, spamtest = train_test_split(spam_list, train_size=0.8)\n",
    "hard_hamtrain, hard_hamtest = train_test_split(hard_ham_list, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2sllUWXKblD",
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "# Write your pre-processing code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnbrbI0_OKCF"
   },
   "source": [
    "### 2. Write a Python program that: \n",
    "1.\tUses the four datasets from Qustion 1 (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) \n",
    "2.\tTrains a Naïve Bayes classifier (use the [scikit-learn library](https://scikit-learn.org/stable/)) on `hamtrain` and `spamtrain`, that classifies the test sets and reports True Positive and False Negative rates on the `hamtest` and `spamtest` datasets. You can use `CountVectorizer` ([Documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)) to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in scikit-learn ([Documentation here](https://scikit-learn.org/stable/modules/naive_bayes.html)). Test two of these classifiers that are well suited for this problem:\n",
    "- Multinomial Naive Bayes  \n",
    "- Bernoulli Naive Bayes. \n",
    "\n",
    "Please inspect the documentation to ensure input to the classifiers is appropriate before you start coding. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "MJERHSCcGNaW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222395023328149\n",
      "0.9642301710730948\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "# vector = vectorizer.get_feature_names()\n",
    "bNB = BernoulliNB()\n",
    "mNB = MultinomialNB()\n",
    "\n",
    "hamspam_train = vectorizer.fit_transform(hamtrain+spamtrain)\n",
    "\n",
    "ham_result = [1 for _ in range(len(hamtrain))]\n",
    "spam_result = [0 for _ in range(len(spamtrain))]\n",
    "\n",
    "hamspam_result = np.array(ham_result+spam_result)\n",
    "\n",
    "bNB.fit(hamspam_train, hamspam_result)\n",
    "mNB.fit(hamspam_train, hamspam_result)\n",
    "\n",
    "\n",
    "\n",
    "hamspam_test = vectorizer.transform(hamtest+spamtest)\n",
    "\n",
    "ham_test_result = [1 for _ in range(len(hamtest))]\n",
    "spam_test_result = [0 for _ in range(len(spamtest))]\n",
    "\n",
    "hamspam_test_result = np.array(ham_test_result+spam_test_result)\n",
    "\n",
    "print(bNB.score(hamspam_test, hamspam_test_result))\n",
    "print(mNB.score(hamspam_test, hamspam_test_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDFS3uFFUcS7"
   },
   "source": [
    "### 3.Run on hard ham:\n",
    "Run the two models from Question 2 on spam versus hard-ham and compare to easy-ham results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gool_zb8Qzzy"
   },
   "outputs": [],
   "source": [
    "#Code to report results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkfQWBB4UhYd"
   },
   "source": [
    "### 4.\tOPTIONAL - NOT MARKED: \n",
    "To avoid classification based on common and uninformative words it is common to filter these out. \n",
    "\n",
    "**a.** Think about why this may be useful. Show a few examples of too common and too uncommon words. \n",
    "\n",
    "**b.** Use the parameters in scikit-learn’s `CountVectorizer` to filter out these words. Update the program from point 2 and run it on easy ham vs spam and hard ham vs spam and report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qt7ELzEqUfas"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcyVfOZFU4F_"
   },
   "source": [
    "### 5. OPTIONAL - NOT MARKED: Eeking out further performance\n",
    "Filter out the headers and footers of the emails before you run on them. The format may vary somewhat between emails, which can make this a bit tricky, so perfect filtering is not required. Run your program again and answer the following questions: \n",
    "- Does the result improve from 3 and 4? \n",
    "- What do you expect would happen if your training set were mostly spam messages while your test set were mostly ham messages or vice versa? \n",
    "- Look at the `fit_prior` parameter. What does this parameter mean? Discuss in what settings it can be helpful (you can also test your hypothesis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkIB6h9k4r07"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From social-admin@linux.ie  Thu Aug 22 16:37:34 2002\n",
      "Return-Path: <social-admin@linux.ie>\n",
      "Delivered-To: zzzz@localhost.example.com\n",
      "Received: from localhost (localhost [127.0.0.1])\n",
      "\tby phobos.labs.example.com (Postfix) with ESMTP id 30B2143F99\n",
      "\tfor <zzzz@localhost>; Thu, 22 Aug 2002 11:37:34 -0400 (EDT)\n",
      "Received: from phobos [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 16:37:34 +0100 (IST)\n",
      "Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7MFYOZ12548 for\n",
      "    <zzzz+ilug-social@jmason.org>; Thu, 22 Aug 2002 16:34:25 +0100\n",
      "Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org\n",
      "    (8.9.3/8.9.3) with ESMTP id QAA07692; Thu, 22 Aug 2002 16:33:43 +0100\n",
      "Received: from email.qves.com ([67.104.83.251]) by lugh.tuatha.org\n",
      "    (8.9.3/8.9.3) with ESMTP id QAA07662 for <social@linux.ie>; Thu,\n",
      "    22 Aug 2002 16:33:37 +0100\n",
      "X-Authentication-Warning: lugh.tuatha.org: Host [67.104.83.251] claimed to\n",
      "    be email.qves.com\n",
      "Received: from qvp0080 ([169.254.6.11]) by email.qves.com with Microsoft\n",
      "    SMTPSVC(5.0.2195.2966); Thu, 22 Aug 2002 09:33:08 -0600\n",
      "From: \"Slim n Trim\" <yenene@mx2.1premio.com>\n",
      "To: <social@linux.ie>\n",
      "Date: Thu, 22 Aug 2002 09:33:07 -0600\n",
      "Message-Id: <104c1101c249f1$36e098b0$0b06fea9@freeyankeedom.com>\n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/plain; charset=\"iso-8859-1\"\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-Mailer: Microsoft CDO for Windows 2000\n",
      "Thread-Index: AcJJ8TbZoOKEj0AtTsKxJ7ZmOA0e/w==\n",
      "Content-Class: urn:content-classes:message\n",
      "X-Mimeole: Produced By Microsoft MimeOLE V6.00.2462.0000\n",
      "X-Originalarrivaltime: 22 Aug 2002 15:33:08.0313 (UTC) FILETIME=[3746D490:01C249F1]\n",
      "Subject: [ILUG-Social] re: Guaranteed to lose 10-12 lbs in 30 days 10.148\n",
      "Sender: social-admin@linux.ie\n",
      "Errors-To: social-admin@linux.ie\n",
      "X-Mailman-Version: 1.1\n",
      "Precedence: bulk\n",
      "List-Id: Irish Linux Users' Group social events <social.linux.ie>\n",
      "X-Beenthere: social@linux.ie\n",
      "\n",
      "I thought you might like these:\n",
      "1) Slim Down - Guaranteed to lose 10-12 lbs in 30 days\n",
      "http://www.freeyankee.com/cgi/fy2/to.cgi?l=822slim1\n",
      "\n",
      "2) Fight The Risk of Cancer! \n",
      "http://www.freeyankee.com/cgi/fy2/to.cgi?l=822nic1 \n",
      "\n",
      "3) Get the Child Support You Deserve - Free Legal Advice \n",
      "http://www.freeyankee.com/cgi/fy2/to.cgi?l=822ppl1\n",
      "\n",
      "Offer Manager\n",
      "Daily-Deals\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "If you wish to leave this list please use the link below.\n",
      "http://www.qves.com/trim/?social@linux.ie%7C29%7C134077\n",
      "\n",
      "\n",
      "-- \n",
      "Irish Linux Users' Group Social Events: social@linux.ie\n",
      "http://www.linux.ie/mailman/listinfo/social for (un)subscription information.\n",
      "List maintainer: listmaster@linux.ie\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('spam/0005.1f42bb885de0ef7fc5cd09d34dc2ba54') as f:\n",
    "    text = f.read()\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c24ecc2928a1df641fb89905a028e959d05eac4f79c1af53f0bb766b01409011"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
