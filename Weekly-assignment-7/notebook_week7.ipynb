{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"9a757983bdca40d58d3f7f9a1fdb66ea","deepnote_cell_type":"markdown","id":"rHoSDyYpdh-s"},"source":["# Assignment 7: Neural Networks using Keras and Tensorflow -- Group 85\n","**Authors: Niclas Lindmark, Noa SjÃ¶strand, Anton Johansson**\n","**Date: 8/2 -23**\n","\n","If you have problems with Keras and Tensorflow on your local installation please make sure they are updated. On Google Colab this notebook runs."]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"4b58eeb798cf43aea0b160c90b3597ad","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2698,"execution_start":1677849054735,"source_hash":"e885af41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n","\n","  Downloading tensorflow-2.12.0rc0-cp311-cp311-win_amd64.whl (1.9 kB)\n","Collecting tensorflow-intel==2.12.0-rc0\n","  Downloading tensorflow_intel-2.12.0rc0-cp311-cp311-win_amd64.whl (272.9 MB)\n","     -------------------------------------- 272.9/272.9 MB 6.6 MB/s eta 0:00:00\n","Collecting absl-py>=1.0.0\n","  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n","     -------------------------------------- 126.5/126.5 kB 7.3 MB/s eta 0:00:00\n","Collecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n","Collecting h5py>=2.9.0\n","  Downloading h5py-3.8.0-cp311-cp311-win_amd64.whl (2.6 MB)\n","     ---------------------------------------- 2.6/2.6 MB 16.7 MB/s eta 0:00:00\n","Collecting jax>=0.3.15\n","  Downloading jax-0.4.5.tar.gz (1.2 MB)\n","     ---------------------------------------- 1.2/1.2 MB 19.4 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting libclang>=13.0.0\n","  Downloading libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n","     --------------------------------------- 23.2/23.2 MB 17.7 MB/s eta 0:00:00\n","Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\anton\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0-rc0->tensorflow) (1.23.5)\n","Collecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n","Requirement already satisfied: packaging in c:\\users\\anton\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0-rc0->tensorflow) (21.3)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n","  Downloading protobuf-4.22.0-cp310-abi3-win_amd64.whl (420 kB)\n","     ------------------------------------- 420.6/420.6 kB 27.4 MB/s eta 0:00:00\n","Requirement already satisfied: setuptools in c:\\users\\anton\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0-rc0->tensorflow) (65.5.0)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\anton\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0-rc0->tensorflow) (1.16.0)\n","Collecting termcolor>=1.1.0\n","  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n","Collecting typing-extensions>=3.6.6\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Collecting wrapt>=1.11.0\n","  Downloading wrapt-1.15.0-cp311-cp311-win_amd64.whl (36 kB)\n","Collecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.51.3-cp311-cp311-win_amd64.whl (3.7 MB)\n","     ---------------------------------------- 3.7/3.7 MB 18.2 MB/s eta 0:00:00\n","Collecting tensorboard<2.13,>=2.12\n","  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n","     ---------------------------------------- 5.6/5.6 MB 18.9 MB/s eta 0:00:00\n","Collecting tensorflow-estimator<2.13,>=2.12.0rc0\n","  Downloading tensorflow_estimator-2.12.0rc0-py2.py3-none-any.whl (440 kB)\n","     ------------------------------------- 440.7/440.7 kB 28.7 MB/s eta 0:00:00\n","Collecting keras<2.13,>=2.12.0rc0\n","  Downloading keras-2.12.0rc1-py2.py3-none-any.whl (1.7 MB)\n","     ---------------------------------------- 1.7/1.7 MB 15.8 MB/s eta 0:00:00\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n","     ---------------------------------------- 1.5/1.5 MB 18.9 MB/s eta 0:00:00\n","Collecting wheel<1.0,>=0.23.0\n","  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n","Requirement already satisfied: scipy>=1.5 in c:\\users\\anton\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0-rc0->tensorflow) (1.10.0)\n","Collecting google-auth<3,>=1.6.3\n","  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n","     ------------------------------------- 177.2/177.2 kB 11.1 MB/s eta 0:00:00\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Collecting markdown>=2.6.8\n","  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n","     ---------------------------------------- 93.3/93.3 kB 5.5 MB/s eta 0:00:00\n","Collecting requests<3,>=2.21.0\n","  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n","     ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n","Collecting tensorboard-plugin-wit>=1.6.0\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","     ------------------------------------- 781.3/781.3 kB 16.4 MB/s eta 0:00:00\n","Collecting werkzeug>=1.0.1\n","  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n","     ------------------------------------- 233.6/233.6 kB 14.9 MB/s eta 0:00:00\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\anton\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0-rc0->tensorflow) (3.0.9)\n","Collecting cachetools<6.0,>=2.0.0\n","  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n","Collecting pyasn1-modules>=0.2.1\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","     ---------------------------------------- 155.3/155.3 kB ? eta 0:00:00\n","Collecting rsa<5,>=3.1.4\n","  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting requests-oauthlib>=0.7.0\n","  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Collecting charset-normalizer<4,>=2\n","  Downloading charset_normalizer-3.0.1-cp311-cp311-win_amd64.whl (96 kB)\n","     ---------------------------------------- 96.0/96.0 kB 5.4 MB/s eta 0:00:00\n","Collecting idna<4,>=2.5\n","  Downloading idna-3.4-py3-none-any.whl (61 kB)\n","     ---------------------------------------- 61.5/61.5 kB 3.4 MB/s eta 0:00:00\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","     -------------------------------------- 140.6/140.6 kB 8.2 MB/s eta 0:00:00\n","Collecting certifi>=2017.4.17\n","  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n","     -------------------------------------- 155.3/155.3 kB 9.1 MB/s eta 0:00:00\n","Collecting MarkupSafe>=2.1.1\n","  Downloading MarkupSafe-2.1.2-cp311-cp311-win_amd64.whl (16 kB)\n","Collecting pyasn1<0.5.0,>=0.4.6\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","     ---------------------------------------- 77.1/77.1 kB ? eta 0:00:00\n","Collecting oauthlib>=3.0.0\n","  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n","     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n","Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, charset-normalizer, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, MarkupSafe, markdown, keras, idna, h5py, grpcio, google-pasta, gast, certifi, cachetools, absl-py, werkzeug, requests, jax, google-auth, astunparse, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n","  Running setup.py install for jax: started\n","  Running setup.py install for jax: finished with status 'done'\n","Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.0.1 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 h5py-3.8.0 idna-3.4 jax-0.4.5 keras-2.12.0rc1 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.22.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorflow-2.12.0rc0 tensorflow-estimator-2.12.0rc0 tensorflow-intel-2.12.0rc0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 typing-extensions-4.5.0 urllib3-1.26.14 werkzeug-2.2.3 wheel-0.38.4 wrapt-1.15.0\n"]},{"name":"stderr","output_type":"stream","text":["  DEPRECATION: jax is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n","\n","[notice] A new release of pip available: 22.3.1 -> 23.0.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["pip install tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"ed2fc42a1d964fcd8ed872faa0b10480","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3829,"execution_start":1677849057437,"id":"02ZYZ-WmdhwH","source_hash":"d31018c1"},"outputs":[],"source":["# imports\n","from __future__ import print_function\n","import keras\n","from keras import utils as np_utils\n","import tensorflow\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","\n","\n","from keras import regularizers \n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"0ed1d64290474e80ba7e3275fe434f91","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":354,"execution_start":1677849061271,"id":"BJRCoRmew8Zd","outputId":"8a74f963-06c8-4ba7-fb03-889e43dfa15e","source_hash":"9f751f85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}],"source":["# Hyper-parameters data-loading and formatting\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 10 # number of times model is trained with all training data\n","\n","img_rows, img_cols = 28, 28\n","\n","(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)"]},{"cell_type":"markdown","metadata":{"cell_id":"29440e3874d64fdc9fcd755876f1c7f2","deepnote_cell_type":"markdown","id":"-I3g1RrZ0wpI"},"source":["**Preprocessing**"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"7f79300cf66d4ec7a1c3a87f1785f96b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5,"execution_start":1677849061633,"source_hash":"c8eb4151","tags":[]},"outputs":[{"data":{"text/plain":["array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["lbl_train"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"443337d7ba3e4f15aef329892a1c6531","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":108,"execution_start":1677849061643,"id":"UswCCQLS0s1I","source_hash":"d68f82c8"},"outputs":[],"source":["x_train = x_train.astype('float32') # changing type to float\n","x_test = x_test.astype('float32') # chainging type to float\n","\n","x_train /= 255 # normalizing the training data from 0-255 to 0-1\n","x_test /= 255 # normalizing the testing data from 0-255 to 0-1\n","\n","y_train = keras.utils.np_utils.to_categorical(lbl_train, num_classes)\n","y_test = keras.utils.np_utils.to_categorical(lbl_test, num_classes)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"10fd5e7d8d5a4ab2a660e2d1831f4f23","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4,"execution_start":1677849061753,"source_hash":"ed857f47","tags":[]},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["y_train"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"9a9b016cc117419e8f9279116911a90a","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":15377,"execution_start":1677849061802,"id":"N7Aer42gk1W9","source_hash":"de1ec0b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4655 - accuracy: 0.8670 - val_loss: 0.2542 - val_accuracy: 0.9268\n","Epoch 2/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.2205 - accuracy: 0.9361 - val_loss: 0.2016 - val_accuracy: 0.9394\n","Epoch 3/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9509 - val_loss: 0.1544 - val_accuracy: 0.9525\n","Epoch 4/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9604 - val_loss: 0.1250 - val_accuracy: 0.9628\n","Epoch 5/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9658 - val_loss: 0.1170 - val_accuracy: 0.9637\n","Epoch 6/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1021 - accuracy: 0.9699 - val_loss: 0.1260 - val_accuracy: 0.9590\n","Epoch 7/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9733 - val_loss: 0.0998 - val_accuracy: 0.9710\n","Epoch 8/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9760 - val_loss: 0.1034 - val_accuracy: 0.9672\n","Epoch 9/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0737 - accuracy: 0.9787 - val_loss: 0.0923 - val_accuracy: 0.9717\n","Epoch 10/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9798 - val_loss: 0.0882 - val_accuracy: 0.9725\n","Test loss: 0.0882074311375618, Test accuracy 0.9725000262260437\n"]}],"source":["\n","## Define model ## \n","## 2 hidden layers ##\n","model = Sequential()\n","\n","model.add(Flatten())\n","model.add(Dense(64, activation = 'relu'))\n","model.add(Dense(64, activation = 'relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","               optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n","        metrics=['accuracy'],)\n","\n","fit_info = model.fit(x_train, y_train,\n","           batch_size=batch_size,\n","           epochs=epochs,\n","           verbose=1,\n","           validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"3b0f408f13334caf8d2ee4b09edee967","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":208354,"execution_start":1677849582166,"source_hash":"69ec9023","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","469/469 [==============================] - 4s 6ms/step - loss: 0.4102 - accuracy: 0.8871 - val_loss: 0.2146 - val_accuracy: 0.9372\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1922 - accuracy: 0.9448 - val_loss: 0.1590 - val_accuracy: 0.9539\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1394 - accuracy: 0.9606 - val_loss: 0.1231 - val_accuracy: 0.9644\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1109 - accuracy: 0.9680 - val_loss: 0.1103 - val_accuracy: 0.9672\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0909 - accuracy: 0.9744 - val_loss: 0.1101 - val_accuracy: 0.9667\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0764 - accuracy: 0.9785 - val_loss: 0.0852 - val_accuracy: 0.9736\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0651 - accuracy: 0.9818 - val_loss: 0.0822 - val_accuracy: 0.9756\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0559 - accuracy: 0.9848 - val_loss: 0.0786 - val_accuracy: 0.9758\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0735 - val_accuracy: 0.9781\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0428 - accuracy: 0.9890 - val_loss: 0.0700 - val_accuracy: 0.9785\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0371 - accuracy: 0.9904 - val_loss: 0.0717 - val_accuracy: 0.9789\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0322 - accuracy: 0.9920 - val_loss: 0.0678 - val_accuracy: 0.9798\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.0649 - val_accuracy: 0.9806\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 0.0640 - val_accuracy: 0.9806\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0219 - accuracy: 0.9956 - val_loss: 0.0649 - val_accuracy: 0.9806\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.0635 - val_accuracy: 0.9806\n","Epoch 17/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.0630 - val_accuracy: 0.9803\n","Epoch 18/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.0644 - val_accuracy: 0.9808\n","Epoch 19/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.0621 - val_accuracy: 0.9818\n","Epoch 20/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0120 - accuracy: 0.9986 - val_loss: 0.0639 - val_accuracy: 0.9810\n","Epoch 21/40\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0110 - accuracy: 0.9987 - val_loss: 0.0644 - val_accuracy: 0.9806\n","Epoch 22/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0624 - val_accuracy: 0.9818\n","Epoch 23/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.0616 - val_accuracy: 0.9828\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.0630 - val_accuracy: 0.9819\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.0624 - val_accuracy: 0.9814\n","Epoch 26/40\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0643 - val_accuracy: 0.9808\n","Epoch 27/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0633 - val_accuracy: 0.9812\n","Epoch 28/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0636 - val_accuracy: 0.9816\n","Epoch 29/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0641 - val_accuracy: 0.9823\n","Epoch 30/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0631 - val_accuracy: 0.9822\n","Epoch 31/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0655 - val_accuracy: 0.9820\n","Epoch 32/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0646 - val_accuracy: 0.9819\n","Epoch 33/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0648 - val_accuracy: 0.9820\n","Epoch 34/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9818\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0657 - val_accuracy: 0.9817\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9819\n","Epoch 37/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9820\n","Epoch 38/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9818\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9816\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9825\n","Regularization factor: 1e-06, Replicate: 1, Test loss: 0.0662710964679718, Test accuracy 0.9825000166893005\n","Epoch 1/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.4053 - accuracy: 0.8874 - val_loss: 0.2268 - val_accuracy: 0.9346\n","Epoch 2/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1912 - accuracy: 0.9457 - val_loss: 0.1508 - val_accuracy: 0.9560\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1383 - accuracy: 0.9602 - val_loss: 0.1289 - val_accuracy: 0.9618\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1085 - accuracy: 0.9693 - val_loss: 0.1068 - val_accuracy: 0.9702\n","Epoch 5/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0881 - accuracy: 0.9750 - val_loss: 0.0917 - val_accuracy: 0.9734\n","Epoch 6/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0740 - accuracy: 0.9794 - val_loss: 0.0856 - val_accuracy: 0.9740\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0620 - accuracy: 0.9827 - val_loss: 0.0830 - val_accuracy: 0.9756\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0538 - accuracy: 0.9855 - val_loss: 0.0716 - val_accuracy: 0.9793\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 0.0773 - val_accuracy: 0.9770\n","Epoch 10/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0407 - accuracy: 0.9895 - val_loss: 0.0739 - val_accuracy: 0.9780\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0351 - accuracy: 0.9913 - val_loss: 0.0667 - val_accuracy: 0.9804\n","Epoch 12/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.0626 - val_accuracy: 0.9807\n","Epoch 13/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.0653 - val_accuracy: 0.9798\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.0606 - val_accuracy: 0.9817\n","Epoch 15/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.0622 - val_accuracy: 0.9817\n","Epoch 16/40\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0617 - val_accuracy: 0.9814\n","Epoch 17/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 0.0625 - val_accuracy: 0.9814\n","Epoch 18/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.0610 - val_accuracy: 0.9806\n","Epoch 19/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.0599 - val_accuracy: 0.9814\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0595 - val_accuracy: 0.9829\n","Epoch 21/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.0606 - val_accuracy: 0.9821\n","Epoch 22/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.0602 - val_accuracy: 0.9817\n","Epoch 23/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.0603 - val_accuracy: 0.9823\n","Epoch 24/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0073 - accuracy: 0.9996 - val_loss: 0.0604 - val_accuracy: 0.9822\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.0607 - val_accuracy: 0.9827\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9831\n","Epoch 27/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0629 - val_accuracy: 0.9820\n","Epoch 28/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0617 - val_accuracy: 0.9830\n","Epoch 29/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0614 - val_accuracy: 0.9836\n","Epoch 30/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0622 - val_accuracy: 0.9829\n","Epoch 31/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0627 - val_accuracy: 0.9831\n","Epoch 32/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0626 - val_accuracy: 0.9824\n","Epoch 33/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9831\n","Epoch 34/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9827\n","Epoch 35/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9829\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9827\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9833\n","Epoch 38/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9823\n","Epoch 39/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9829\n","Epoch 40/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9824\n","Regularization factor: 1e-06, Replicate: 2, Test loss: 0.06534123420715332, Test accuracy 0.9824000000953674\n","Epoch 1/40\n","469/469 [==============================] - 4s 7ms/step - loss: 0.4013 - accuracy: 0.8882 - val_loss: 0.2179 - val_accuracy: 0.9356\n","Epoch 2/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1920 - accuracy: 0.9449 - val_loss: 0.1545 - val_accuracy: 0.9547\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1396 - accuracy: 0.9606 - val_loss: 0.1325 - val_accuracy: 0.9608\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1103 - accuracy: 0.9692 - val_loss: 0.1072 - val_accuracy: 0.9686\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0900 - accuracy: 0.9746 - val_loss: 0.1101 - val_accuracy: 0.9679\n","Epoch 6/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0753 - accuracy: 0.9786 - val_loss: 0.0872 - val_accuracy: 0.9726\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0642 - accuracy: 0.9821 - val_loss: 0.0782 - val_accuracy: 0.9754\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0547 - accuracy: 0.9852 - val_loss: 0.0808 - val_accuracy: 0.9746\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0472 - accuracy: 0.9872 - val_loss: 0.0742 - val_accuracy: 0.9760\n","Epoch 10/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0408 - accuracy: 0.9891 - val_loss: 0.0704 - val_accuracy: 0.9777\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 0.0710 - val_accuracy: 0.9767\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.0680 - val_accuracy: 0.9783\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0270 - accuracy: 0.9940 - val_loss: 0.0679 - val_accuracy: 0.9784\n","Epoch 14/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0208 - accuracy: 0.9959 - val_loss: 0.0641 - val_accuracy: 0.9792\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 0.0608 - val_accuracy: 0.9810\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.0627 - val_accuracy: 0.9806\n","Epoch 18/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0144 - accuracy: 0.9978 - val_loss: 0.0637 - val_accuracy: 0.9795\n","Epoch 19/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.0641 - val_accuracy: 0.9791\n","Epoch 20/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.0625 - val_accuracy: 0.9804\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.0634 - val_accuracy: 0.9806\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.0684 - val_accuracy: 0.9782\n","Epoch 23/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.0643 - val_accuracy: 0.9803\n","Epoch 24/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.0658 - val_accuracy: 0.9806\n","Epoch 25/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0643 - val_accuracy: 0.9807\n","Epoch 26/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0630 - val_accuracy: 0.9806\n","Epoch 27/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9802\n","Epoch 28/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0648 - val_accuracy: 0.9800\n","Epoch 29/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0658 - val_accuracy: 0.9804\n","Epoch 30/40\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9803\n","Epoch 31/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0657 - val_accuracy: 0.9804\n","Epoch 32/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0664 - val_accuracy: 0.9805\n","Epoch 33/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0666 - val_accuracy: 0.9807\n","Epoch 34/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0673 - val_accuracy: 0.9804\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9810\n","Epoch 36/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9811\n","Epoch 37/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9808\n","Epoch 38/40\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9806\n","Epoch 39/40\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9804\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9806\n","Regularization factor: 1e-06, Replicate: 3, Test loss: 0.06850174814462662, Test accuracy 0.9805999994277954\n","Epoch 1/40\n","469/469 [==============================] - 4s 7ms/step - loss: 0.4112 - accuracy: 0.8884 - val_loss: 0.2669 - val_accuracy: 0.9227\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1996 - accuracy: 0.9461 - val_loss: 0.1615 - val_accuracy: 0.9544\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1475 - accuracy: 0.9601 - val_loss: 0.1293 - val_accuracy: 0.9648\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1181 - accuracy: 0.9689 - val_loss: 0.1137 - val_accuracy: 0.9696\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0985 - accuracy: 0.9746 - val_loss: 0.1031 - val_accuracy: 0.9716\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0837 - accuracy: 0.9790 - val_loss: 0.0938 - val_accuracy: 0.9758\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0730 - accuracy: 0.9826 - val_loss: 0.0978 - val_accuracy: 0.9734\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0643 - accuracy: 0.9847 - val_loss: 0.0841 - val_accuracy: 0.9772\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0569 - accuracy: 0.9874 - val_loss: 0.0825 - val_accuracy: 0.9785\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0506 - accuracy: 0.9893 - val_loss: 0.0822 - val_accuracy: 0.9775\n","Epoch 11/40\n","105/469 [=====>........................] - ETA: 2s - loss: 0.0453 - accuracy: 0.9906"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     13\u001b[0m model\u001b[39m.\u001b[39madd(Dense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     16\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mcategorical_crossentropy,\n\u001b[0;32m     17\u001b[0m             optimizer\u001b[39m=\u001b[39mtensorflow\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m),\n\u001b[0;32m     18\u001b[0m         metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m],)\n\u001b[1;32m---> 20\u001b[0m fit_info \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train,\n\u001b[0;32m     21\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     22\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     23\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     24\u001b[0m         validation_data\u001b[39m=\u001b[39;49m(x_test, y_test))\n\u001b[0;32m     25\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRegularization factor: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Replicate: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Test loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Test accuracy \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     27\u001b[0m             reg_factor, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, score[\u001b[39m0\u001b[39m], score[\u001b[39m1\u001b[39m]))\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["## Define model ##\n","## 3 hidden layers ##\n","\n","epochs = 40 \n","reg_factors = [0.000001, 0.00001, 0.0001, 0.0005, 0.001]\n","\n","for reg_factor in reg_factors:\n","    for i in range(3):\n","        model = Sequential()\n","        model.add(Flatten())\n","        model.add(Dense(500, activation = 'relu', kernel_regularizer=regularizers.l2(reg_factor)))\n","        model.add(Dense(300, activation = 'relu', kernel_regularizer=regularizers.l2(reg_factor)))\n","        model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","        model.compile(loss=keras.losses.categorical_crossentropy,\n","                    optimizer=tensorflow.keras.optimizers.SGD(learning_rate = 0.1),\n","                metrics=['accuracy'],)\n","\n","        fit_info = model.fit(x_train, y_train,\n","                batch_size=batch_size,\n","                epochs=epochs,\n","                verbose=1,\n","                validation_data=(x_test, y_test))\n","        score = model.evaluate(x_test, y_test, verbose=0)\n","        print('Regularization factor: {}, Replicate: {}, Test loss: {}, Test accuracy {}'.format(\n","                    reg_factor, i+1, score[0], score[1]))"]},{"cell_type":"markdown","metadata":{"cell_id":"e12d9ce892bc403da28fd57bc801b8b2","deepnote_cell_type":"markdown","tags":[]},"source":["## 1. Preprocessing.\n","In  the  notebook,  the  data  is  downloaded  from  an  external  server  and im-ported into the notebook environment using the mnist.load_data() function call. \n"," \n","1.1. Explain the data pre-processing highlighted in the notebook \n"," \n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"7d6a9bcb5e724502996292390001fd1a","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":8,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["Answer: "]},{"cell_type":"markdown","metadata":{"cell_id":"3ac1a91e8d964dda88c09a2e7c1938e5","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["Firstly, the data is transformed from integers to float values. This is because the values are going to be multiplied with various weights (between the layers in the neural network) which will be of type float. Changing the type makes it compatible with the model."]},{"cell_type":"markdown","metadata":{"cell_id":"b60311ed-66e5-4fb5-b96f-db14f3b31a0b","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["Secondly, the data is divided with 255. This is to normalise the pixel values to a range between 0 and 1. Doing this makes it easier for the neural network to recognise patterns and relationships in the provided data. This should result in faster training times and better performance."]},{"cell_type":"markdown","metadata":{"cell_id":"d5c3c246-a6ed-4040-a9ba-d434b33eda87","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["Lastly, the label data for both the training and test sets are converted into a binary matrix using the to_categorical function. This is necessary because the training of the neural network require label data to be in a binary format (either the result is a 1 or not a 1). In other words, the label data is transformed from being in a \"list\" format [1, 2, 2, ..., 5, 2, 9] describing what number where drawn in each sample of the test data, as an integer. to a matrix describing wether the result is a certain number or not. For example, [1, 2, 3] would be transformed to [[0, 1, 0, ...], [0, 0, 1, ...], [0, 0, 0, 1, ...]]. "]},{"cell_type":"markdown","metadata":{"cell_id":"b17d3768-ed44-413b-9ed9-80a95b8ea118","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["There are 2 ways to convert categorical data to numerical data, either integer encoding or one-hot encoding. Integer encoding is where each label is represented by a number, one-hot encoding is thorough a binary matrix like the one in the previous paragraph. In this case we are using one-hot encoding. "]},{"cell_type":"markdown","metadata":{"cell_id":"b27caa29-fe46-4341-b68f-732d8edcfd3c","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"48c228fdf8084defb1c8542a0768eaff","deepnote_cell_type":"markdown","tags":[]},"source":["## 2. Network model, training, and changing hyper-parameters \n"," \n","2.1. How  many  layers  does  the  network  in  the  notebook  have?  How  many  neurons  does \n","each layer have? What activation functions and why are these appropriate for this ap-\n","plication? What is the total number of parameters for the network? Why do the input \n","and output layers have the dimensions they have? \n"," \n","2.2. What loss function is used to train the network? What is the functional form (a math-\n","ematical  expression)  of  the  loss  function?  and  how  should  we  interpret  it?  Why  is  it \n","appropriate for the problem at hand? \n"," \n","2.3. Train the network for 10 epochs and plot the training and validation accuracy for each \n","epoch. \n"," \n","2.4. Update the model to implement a three-layer neural network where the hidden layers \n","have 500 and 300 hidden units respectively. Train for 40 epochs. What is the best vali-\n","dation  accuracy  you  can  achieve?  â  Geoff  Hinton  (a  co-pioneer  of  Deep  learning) \n","claimed this network could reach a validation accuracy of 0.9847 \n","(http://yann.lecun.com/exdb/mnist/) using weight decay (L2 regularization of weights (kernels): https://keras.io/api/layers/regularizers/).  Implement  weight  decay  on  hid-\n","den units and train and select 5 regularization factors from 0.000001 to 0.001. Train 3 \n","replicates  networks  for  each  regularization  factor.  Plot  the  final  validation  accuracy \n","with standard deviation (computed from the replicates) as a function of the regulari-\n","zation  factor.  How  close  do  you  get  to  Hintons  result?  â  If  you  do  not  get  the  same \n","results, what factors may influence this? (hint: What information is not given by Hinton \n","on the MNIST database that may influence Model training)  "]},{"cell_type":"markdown","metadata":{"cell_id":"32c693d939fa4ba19eb47af6f21f1077","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":9,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["Answers: "]},{"cell_type":"markdown","metadata":{"cell_id":"188c6253-3f94-44fb-94a5-9338c9d24a41","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":1,"marks":{"bold":true},"toCodePoint":5,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":[" 2.1)   There are 3 layers in total."]},{"cell_type":"markdown","metadata":{"cell_id":"be888f98-8044-45ac-b8b8-451c2a5a8240","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The first \"layer\" is flattening the 28x28 matrices to a 1D vector with 784 elements. This is the input layer and doesn't compute anything, thus we don't count it as a layer."]},{"cell_type":"markdown","metadata":{"cell_id":"66028923-9962-4976-ac8e-421319b4e3d1","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The remaining layers uses activation functions which decides whether you should activate a neuron or not, and if activated the function decides the output of that neuron."]},{"cell_type":"markdown","metadata":{"cell_id":"3365c9f9-86bc-4199-b110-0da6995f1d99","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The first and second \"real\" layers are hidden layers with 64 neurons each using ReLU activation function. ReLu is a common activation function for the hidden layers because it often result in better performance and training. It outputs the maximum of 0 and the input value. One reason why this trains the models faster is because compared to other activation functions it does not activate all neurons in the layer, only the ones with a positive input. "]},{"cell_type":"markdown","metadata":{"cell_id":"ef074e98-b5c1-4cb5-8a4b-298c0b78bb05","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The third layer has 10 neurons, one for each possible output number (0-9), and uses Softmax activation, transforming input numbers into probabilities of possible outcomes and is generally used in the output layer of a NN. This allows the network to classify based on probability of being one of the classes given. "]},{"cell_type":"markdown","metadata":{"cell_id":"eeb94cdb17164be3b20be1b03c78a844","deepnote_cell_type":"markdown","tags":[]},"source":["![Picture title](image-20230302-173828.png)"]},{"cell_type":"markdown","metadata":{"cell_id":"3d0538fc0c02402d9d41d5440b2041ce","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"6b65a184-e173-49e7-b270-701f2d159b09","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["We have calculated the total amount of parameters in the following way:"]},{"cell_type":"markdown","metadata":{"cell_id":"15300cb6-c05f-4e8a-b5ff-7f959a1c59da","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":583,"marks":{"bold":true},"toCodePoint":589,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["The flatten layer has no trainable parameters.\n","The first dense layer has 64 * (784 + 1) = 50,240 trainable parameters, where 784 is the number of pixels in the input image (28x28) and 1 is for the bias term. There is only 1 bias term in each layer since the bias term is shared across all neurons in that layer. That means the bias term affects the output of the entire layer.\n","The second dense layer has 64 * (64 + 1) = 4,160 trainable parameters.\n","The output dense layer has 10 * (64 + 1) = 650 trainable parameters.\n","Total number of trainable parameters = 50,240 + 4,160 + 650 = 54,050."]},{"cell_type":"markdown","metadata":{"cell_id":"10fadf3b-e368-4fd3-b719-07645ba080ce","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The input layer has dimension 784 because the input images are grayscale with dimensions 28x28. The output layer has dimension 10 because there are 10 possible numbers to output."]},{"cell_type":"markdown","metadata":{"cell_id":"d14bc750-0e1e-4270-b7d7-6c43fd70e123","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":5,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":[" 2.2) The used loss function is cross-entropy, as specified in the code. An advantage of cross-entropy is that it can handle multiple classes well, making it suitable for this task where we are trying to classify images into 10 different classes.  "]},{"cell_type":"markdown","metadata":{"cell_id":"ab5dad43-7cd2-4b56-9d2a-54dced35a821","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The mathematical formula for cross-entropy is shown below. When we multiply the true label with the predicted probability, we are only keeping the element of the true class in the 1D vector. This is because the true label vector is 1 for the true class and 0 for all other classes, for example [0,0,0,0,1,0,0]. All the other labels are multiplied with 0 and lose their value. That means this calculation takes the log of the predicted probability for the true class and multiplying it by -1."]},{"cell_type":"markdown","metadata":{"cell_id":"1010db7a-b0e2-4839-8577-204b97e1ac75","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"b52cdabfaaab46f9b2c357ef7d23626b","deepnote_cell_type":"markdown","tags":[]},"source":["![Picture title](image-20230302-194014.png)"]},{"cell_type":"markdown","metadata":{"cell_id":"0361642c-24f3-4efd-b18d-b601fe3ff27c","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":[" 2.3) See prints"]},{"cell_type":"markdown","metadata":{"cell_id":"c00d4ad2-e0a4-4342-8052-71824027ff8a","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":1,"marks":{"bold":true},"toCodePoint":6,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":[" 2.4) L2 regularization, also known as weight decay, is a technique used to prevent overfitting in machine learning models by adding a penalty term to the loss function. The penalty term is proportional to the square of the weights in the network, which encourages the network to learn smaller weight values. This technique aims to simplify the model by shrinking the weights toward zero, reducing the model complexity, and thus improving its generalization ability. "]},{"cell_type":"markdown","metadata":{"cell_id":"e29f1172-fbe0-40ee-aed9-24165f9dc956","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The regularization factor determines how much the penalty term contributes to the overall loss function during training. A higher regularization factor will make the weights smaller. On the other hand, a lower regularization factor will result in bigger weights. That means that choosing a too-high value can lead to underfitting, while a too-low value can lead to overfitting. "]},{"cell_type":"markdown","metadata":{"cell_id":"efa44c4e-0ae9-4e81-8d2b-57369a2a9d90","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"83155d3b-0da1-4381-bb8e-1065f057571d","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":0,"type":"marks"}],"is_collapsed":false,"number":2,"style":"decimal","tags":[]},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0aea5b47a22942bdb16d7a37fb01fd96","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":76674489,"execution_start":1677772434662,"source_hash":"b623e53d","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"4436cf6ffd0847da9552c9862aaeac77","deepnote_cell_type":"markdown","tags":[]},"source":["## 3. Convolutional layers \n"," \n","3.1. Design a model that makes use of at least one convolutional layer â how performant a \n","model can you get? -- According to the MNIST database it should be possible reach to \n","99%  accuracy  on  the  validation  data.  If  you  choose  to  use  any  layers  apart  from  the \n","convolutional layers and layers that you used in previous questions, you must describe \n","what  they  do.  If  you  do not  reach 99%  accuracy,  report  your  best  performance,  and \n","explain your attempts and thought process. \n"," \n","3.2. Discuss the differences and potential benefits of using convolutional layers over fully \n","connected ones for the application?  \n"]},{"cell_type":"markdown","metadata":{"cell_id":"3de6434b2f144132b9e28e4537ebebc6","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":8,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["Answer: ..."]},{"cell_type":"markdown","metadata":{"cell_id":"f3ad7563-a9d8-42d0-a6c3-740a17f72033","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["A convolutional layer is a set of filters applied to the input image. The \"filters\" can help the model focus on certain parts of the image, making it better suited for certain tasks, such as detecting edges, shapes, and textures."]},{"cell_type":"markdown","metadata":{"cell_id":"24f38a3f-aa3d-42a3-9d90-c6f91aa30bd3","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ed0c436b-4e08-4c3b-a423-80f934892d31' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Assignment_7_NN.ipynb","provenance":[]},"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"2a5d613444a54afab843e2f9addee4bd","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"8b3862bff8ec4c0913ff501ec59a91eeec109cc3060137e5ac68f23925615549"}}},"nbformat":4,"nbformat_minor":0}
